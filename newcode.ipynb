{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "newcode.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejrrKBJEmJih",
        "colab_type": "text"
      },
      "source": [
        "Researchers have access to large online archives of scientific articles. As a consequence, finding relevant articles has become more difficult. Tagging or topic modelling provides a way to give token of identification to research articles which facilitates recommendation and search process.\n",
        "Given the abstract and title for a set of research articles, predict the topics for each article included in the test set. \n",
        "Note that a research article can possibly have more than 1 topic. The research article abstracts and titles are sourced from the following 6 topics: \n",
        "1. Computer Science\n",
        "\n",
        "2. Physics\n",
        "\n",
        "3. Mathematics\n",
        "\n",
        "4. Statistics\n",
        "\n",
        "5. Quantitative Biology\n",
        "\n",
        "6. Quantitative Finance\n",
        "\n",
        "Submissions are evaluated on micro F1 Score between the predicted and observed topics for each article in the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzRoZjOZma6-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "6299172b-f49c-42a3-8c3d-6c8b67b6faa6"
      },
      "source": [
        "!pip install scikit-multilearn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-multilearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/1f/e6ff649c72a1cdf2c7a1d31eb21705110ce1c5d3e7e26b2cc300e1637272/scikit_multilearn-0.2.0-py3-none-any.whl (89kB)\n",
            "\r\u001b[K     |███▊                            | 10kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 2.4MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-1v_LInmJik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "from pprint import pprint\n",
        "from time import time\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import sys\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline,FeatureUnion\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from skmultilearn.problem_transform import ClassifierChain\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from skmultilearn.problem_transform import BinaryRelevance\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from skmultilearn.problem_transform import LabelPowerset\n",
        "from skmultilearn.adapt import MLkNN\n",
        "from scipy.sparse import csr_matrix, lil_matrix\n",
        "from skmultilearn.problem_transform import LabelPowerset\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score, make_scorer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPFaiZzKmJit",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "13f0f466-353c-4cc6-94da-8071b7922f8e"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import wordnet\n",
        "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
        "en_stop.update(['zero','one','two','three','four','five','six','seven','eight','nine','ten','may','also','across',\n",
        "                'among','beside','however','yet','within'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWDbmkkdmJi2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "outputId": "d6a8b454-ee1d-4edc-ca29-8e20d6a9805b"
      },
      "source": [
        "raw_data = pd.read_csv('train.csv')\n",
        "raw_data.head(1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ABSTRACT</th>\n",
              "      <th>Computer Science</th>\n",
              "      <th>Physics</th>\n",
              "      <th>Mathematics</th>\n",
              "      <th>Statistics</th>\n",
              "      <th>Quantitative Biology</th>\n",
              "      <th>Quantitative Finance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
              "      <td>Predictive models allow subject-specific inf...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID  ... Quantitative Finance\n",
              "0   1  ...                    0\n",
              "\n",
              "[1 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnUsvtuXmJi-",
        "colab_type": "code",
        "colab": {},
        "outputId": "68d596c7-edd3-46be-f0ba-62b43393437f"
      },
      "source": [
        "#EDA: to check the composition of classes\n",
        "data = raw_data.iloc[:,3:]\n",
        "plt.figure(figsize=(15,5))\n",
        "lables = data.sum().values\n",
        "ax = sns.barplot(data.columns,lables)\n",
        "\n",
        "rects = ax.patches\n",
        "for rect,lable in zip(rects,lables):\n",
        "    height = rect.get_height()\n",
        "    ax.text(rect.get_x()+rect.get_width()/2,height+5,lable,ha='center',va='bottom')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYhaIIvfmJjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preprocessing\n",
        "data = raw_data.copy()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLs8oJ4P0-EZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import TransformerMixin, BaseEstimator\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "import re\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "import pandas\n",
        "\n",
        "class preTransformer(BaseEstimator,TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.re_stop_words = re.compile(r'\\b(' + '|'.join(en_stop) + ')\\\\W', re.I)\n",
        "        self.stemmer = PorterStemmer()\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "        pass\n",
        "        \n",
        "    def fit(self,df,y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self,df,y=None):\n",
        "        df['ABSTRACT'] = df['ABSTRACT'].apply(self.preprocess)\n",
        "        df['TITLE'] = df['TITLE'].apply(self.preprocess)\n",
        "    \n",
        "    def getPosTagDef(self,postag):\n",
        "        if postag in ['JJ', 'JJR', 'JJS']:\n",
        "            return wordnet.ADJ\n",
        "        elif postag in ['RB', 'RBR', 'RBS']:\n",
        "            return wordnet.ADV\n",
        "        elif postag in ['NN', 'NNS', 'NNP', 'NNPS']:\n",
        "            return wordnet.NOUN\n",
        "        elif postag in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']:\n",
        "            return wordnet.VERB\n",
        "        else:\n",
        "            return None\n",
        "    def preprocess(self,string):\n",
        "        result=[]\n",
        "        #clean\n",
        "        string = re.sub('[!”#$%&’()*+,-./:;<=>?@[\\]^_`{|}~\\n]',' ',string)\n",
        "        string = re.sub(r'[^a-zA-Z ]','',string)\n",
        "        string = re.sub(r'\\b\\w{1,2}\\b', '', string)\n",
        "        #stop words\n",
        "        string = self.re_stop_words.sub(' ',string)\n",
        "        #stemming\n",
        "        string = ' '.join([self.stemmer.stem(x.strip()) for x in string.split()])\n",
        "        #lemmatize\n",
        "        pos_tags = nltk.pos_tag(string.split())\n",
        "        for token,postag in pos_tags:    \n",
        "            pos = self.getPosTagDef(postag)\n",
        "            if pos != None:\n",
        "                  result.append(self.lemmatizer.lemmatize(token,pos))\n",
        "            else:\n",
        "                  result.append( self.lemmatizer.lemmatize(token))\n",
        "        return ' '.join(result)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3omipeCvRp9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preprocess pipeline\n",
        "data = raw_data.copy()\n",
        "pretr = preTransformer()\n",
        "pretr.fit_transform(data)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7V8k0pLmJjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model\n",
        "\n",
        "X = data['ABSTRACT']\n",
        "y = data.iloc[:,3:]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "\n",
        "\n",
        "classifiers = [\n",
        "    #BinaryRelevance(GaussianNB()),\n",
        "    #ClassifierChain(LogisticRegression()),\n",
        "    LabelPowerset(LogisticRegression()), #76\n",
        "    #MLkNN(),\n",
        "    #LabelPowerset(GaussianNB()) #56\n",
        "]\n",
        "check_params = {\n",
        "    'vect__max_df': (0.5, 0.75, 1.0,2.0),\n",
        "    'vect__max_features': (50,100,200,300),\n",
        "    'vect__ngram_range': ((1, 1), (1, 2),(1,3)),  # unigrams or bigrams\n",
        "    'tfidf__use_idf': (True, False),\n",
        "    'tfidf__norm': ('l1', 'l2')\n",
        "}\n",
        "cvrange = range(4,6)\n",
        "for classifier in classifiers:\n",
        "    pipe = Pipeline([('vect',CountVectorizer()), ('tfidf', TfidfTransformer()),('model',classifier)])\n",
        "    print(classifier)\n",
        "    with tqdm(total=len(range(4,6))) as bar:\n",
        "        for cv in tqdm(range(4,6)):\n",
        "          Gsc = GridSearchCV(estimator=pipe,param_grid=check_params, cv=cv,scoring='f1_micro')\n",
        "          Gsc.fit(X_train,y_train)\n",
        "          print('score   : %3.2f' %(  Gsc.score(X_test,y_test)))\n",
        "          print('best_params :', [(k,v) for (k,v) in Gsc.best_params_.items()])\n",
        "          bar.update(1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKaVUfcGxs7V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce3b527f-4f00-444a-d7c6-632df2243921"
      },
      "source": [
        "X = data['ABSTRACT']\n",
        "y = data.iloc[:,3:]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "\n",
        "classifiers = [\n",
        "    #BinaryRelevance(GaussianNB()),\n",
        "    #ClassifierChain(LogisticRegression()),\n",
        "    LabelPowerset(LogisticRegression()), #76\n",
        "    #MLkNN(),\n",
        "    #LabelPowerset(GaussianNB()) #56\n",
        "]\n",
        "check_params = {\n",
        "    'tfidf__use_idf': (True, False),\n",
        "    'tfidf__norm': ('l1', 'l2'),\n",
        "    'tfidf__max_df': (0.5, 0.75, 1.0,2.0),\n",
        "    'tfidf__max_features': (50,100,200,300),\n",
        "    'tfidf__ngram_range': ((1, 1), (1, 2),(1,3))  # unigrams or bigrams\n",
        "}\n",
        "cvrange = range(4,6)\n",
        "for classifier in classifiers:\n",
        "    pipe = Pipeline([('tfidf', TfidfVectorizer()),('model',classifier)])\n",
        "    print(classifier)\n",
        "    with tqdm(total=len(range(4,6))) as bar:\n",
        "        for cv in tqdm(range(4,6)):\n",
        "          Gsc = GridSearchCV(estimator=pipe,param_grid=check_params, cv=cv,scoring='f1_micro')\n",
        "          Gsc.fit(X_train,y_train)\n",
        "          print('score   : %3.2f' %(  Gsc.score(X_test,y_test)))\n",
        "          print('best_params :', [(k,v) for (k,v) in Gsc.best_params_.items()])\n",
        "          bar.update(1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2 [00:00<?, ?it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LabelPowerset(classifier=LogisticRegression(C=1.0, class_weight=None,\n",
            "                                            dual=False, fit_intercept=True,\n",
            "                                            intercept_scaling=1, l1_ratio=None,\n",
            "                                            max_iter=100, multi_class='auto',\n",
            "                                            n_jobs=None, penalty='l2',\n",
            "                                            random_state=None, solver='lbfgs',\n",
            "                                            tol=0.0001, verbose=0,\n",
            "                                            warm_start=False),\n",
            "              require_dense=[True, True])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/2 [1:20:56<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-3543a3438079>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m           \u001b[0mGsc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1_micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m           \u001b[0mGsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'score   : %3.2f'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mGsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_params :'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    352\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skmultilearn/problem_transform/lp.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         self.classifier.fit(self._ensure_input_format(X),\n\u001b[0;32m--> 141\u001b[0;31m                             self.transform(y))\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1599\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1601\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m                 \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"iprint\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gtol\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"maxiter\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m             )\n\u001b[1;32m    938\u001b[0m             n_iter_i = _check_optimize_result(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 610\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, *args)\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_multi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_multinomial_loss_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_multinomial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_multinomial_loss_grad\u001b[0;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    347\u001b[0m     grad = np.zeros((n_classes, n_features + bool(fit_intercept)),\n\u001b[1;32m    348\u001b[0m                     dtype=X.dtype)\n\u001b[0;32m--> 349\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_multinomial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m     \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_multinomial_loss\u001b[0;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mintercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mintercept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUaXTKH5yRzW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data[['TITLE','ABSTRACT']]\n",
        "def getTitle():\n",
        "  return data['TITLE']\n",
        "\n",
        "def getAbstract():\n",
        "  return  data['ABSTRACT']\n",
        "\n",
        "y = data.iloc[:,3:]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "\n",
        "classifiers = [\n",
        "    #BinaryRelevance(GaussianNB()),\n",
        "    #ClassifierChain(LogisticRegression()),\n",
        "    LabelPowerset(LogisticRegression()), #76\n",
        "    #MLkNN(),\n",
        "    #LabelPowerset(GaussianNB()) #56\n",
        "]\n",
        "check_params = {\n",
        "    'pipe_title__tfidf__use_idf': (True, False),\n",
        "    'pipe_title__tfidf__norm': ('l1', 'l2'),\n",
        "    'pipe_title__tfidf__max_df': (0.5, 0.75, 1.0,2.0),\n",
        "    'pipe_title__tfidf__max_features': (50,100,200,300),\n",
        "    'pipe_title__tfidf__ngram_range': ((1, 1), (1, 2),(1,3)),  # unigrams or bigrams\n",
        "\n",
        "    'pipe_abstract__tfidf__use_idf': (True, False),\n",
        "    'pipe_abstract__tfidf__norm': ('l1', 'l2')\n",
        "    'pipe_abstract__tfidf__max_df': (0.5, 0.75, 1.0,2.0),\n",
        "    'pipe_abstract__tfidf__max_features': (50,100,200,300),\n",
        "    'pipe_abstract__tfidf__ngram_range': ((1, 1), (1, 2),(1,3))  # unigrams or bigrams\n",
        "}\n",
        "cvrange = range(4,6)\n",
        "pipe_title = Pipeline([('col_sel',FunctionTransformer(getTitle,validate=False) ), ('tfidf', TfidfVectorizer())])\n",
        "pipe_abstract = Pipeline([('col_sel',FunctionTransformer(getAbstract,validate=False) ), ('tfidf', TfidfVectorizer())])\n",
        "\n",
        "for classifier in classifiers:\n",
        "    pipe = Pipeline([FeatureUnion([('pipe_title',pipe_title),('pipe_abstract',pipe_abstract)]),('model',classifier)])\n",
        "    print(classifier)\n",
        "    with tqdm(total=len(range(4,6))) as bar:\n",
        "        for cv in tqdm(range(4,6)):\n",
        "          Gsc = GridSearchCV(estimator=pipe,param_grid=check_params, cv=cv,scoring='f1_micro')\n",
        "          Gsc.fit(X_train,y_train)\n",
        "          print('score   : %3.2f' %(  Gsc.score(X_test,y_test)))\n",
        "          print('best_params :', [(k,v) for (k,v) in Gsc.best_params_.items()])\n",
        "          bar.update(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsdHb9kPmJjr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3b3699f-02f5-4428-f233-a9dc401768d2"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "data = raw_data.copy()\n",
        "pretr = preTransformer()\n",
        "pretr.fit_transform(data)\n",
        "\n",
        "X = data['ABSTRACT']\n",
        "y = data.iloc[:,3:]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "\n",
        "model = LabelPowerset(classifier=LogisticRegression(C=1.0, class_weight=None,\n",
        "                                            dual=False, fit_intercept=True,\n",
        "                                            intercept_scaling=1, l1_ratio=None,\n",
        "                                            max_iter=100, multi_class='auto',\n",
        "                                            n_jobs=None, penalty='l2',\n",
        "                                            random_state=None, solver='lbfgs',\n",
        "                                            tol=0.0001, verbose=0, warm_start=False))\n",
        "pipe = Pipeline([('vect', CountVectorizer(max_df=0.5,max_features=300,ngram_range=(1,2))),('tfidf', TfidfTransformer(norm='l2',use_idf=True)),('model',model)])\n",
        "pipe.fit(X_train,y_train)\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "print('Accuracy on test data: {:.1f}%'.format(f1_score(y_test, y_pred, average='micro')*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test data: 76.3%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNO6NQ8Whf7L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5458d086-344a-4e91-e892-f575615bcbe3"
      },
      "source": [
        "test_data = pd.read_csv('test.csv')\n",
        "pretr.transform(test_data)\n",
        "\n",
        "X_test_data = test_data['ABSTRACT']\n",
        "y_test_data = pipe.predict(X_test_data)\n",
        "y_test_data\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<8989x6 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 10410 stored elements in List of Lists format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJBLF_TIk3Lg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_res = y_test_data.todense()\n",
        "res = pd.DataFrame(columns=y.columns,data=y_res)\n",
        "res.insert(0,'ID',test_data['ID'])\n",
        "res.iloc[:,0:].to_csv('sample_submission.csv',index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEymBNX3lMLZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27011d48-8edb-44eb-8b38-4a6c73bc79e1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.lil.lil_matrix"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDFc9Xy-leme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}